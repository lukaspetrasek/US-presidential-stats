{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US presidential statistics\n",
    "## Simon Repko, Lukas Petrasek\n",
    "### IES FSS CU\n",
    "### 31.5.2019\n",
    "\n",
    "This notebook serves as a demonstration of a school project whose goal is to achieve the following:\n",
    "* scrape web pages to get historical data on US presidents\n",
    "* manipulate the data into a form suitable for being visualized\n",
    "* make vizualizations based the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, Type\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: initialize the scraping class and apply the methods necessary to get the data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url: str) -> BeautifulSoup:\n",
    "    ''' Returns soup for the given url. '''\n",
    "    return BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "\n",
    "\n",
    "\n",
    "class MillerScraper:\n",
    "    '''\n",
    "    Class for scraping the Miller Center webpage to get data about US presidents. \n",
    "\n",
    "    Particularly, it serves for scraping data on facts and characteristics (self.fast_facts), \n",
    "    brief description (self.descriptions), famous quotes (self.famous_quotes), and count of \n",
    "    notable events happened during the president's office (self.key_events_counts).\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        ''' Initializes the scraping class. '''\n",
    "        self.origin: str = 'https://millercenter.org/'\n",
    "\n",
    "        self.subdirectories: Optional[Dict[str, Any]] = None\n",
    "\n",
    "        self.fast_facts: Optional[Dict[str, Any]] = None\n",
    "        self.descriptions: Optional[Dict[str, Any]] = None\n",
    "        self.famous_quotes: Optional[Dict[str, Any]] = None\n",
    "        self.key_events_counts: Optional[Dict[str, Any]] = None\n",
    "\n",
    "        self.all_presidents_data: Optional[pd.DataFrame()] = None\n",
    "\n",
    "\n",
    "    def get_subdirectories(self) -> None:\n",
    "        '''\n",
    "        Creates a dictionary with the presidents' names as keys and their respective \n",
    "        subdirectories as values, then saves the dictionary to self.subdirectories.\n",
    "        '''\n",
    "        # parse the given origin (web address) utilizing BeautifulSoup \n",
    "        soup = get_soup(self.origin) \n",
    "        # enter the main navigation panel and find submenu that contains the links \n",
    "        # (subdirectories) to individual pages of US presidents\n",
    "        navigation_menu = soup.find('nav', {'aria-labelledby':'block-mainnavigation-3-menu'})\n",
    "        submenu = navigation_menu.find_all('ul', {'class':'submenu'})[1]\n",
    "        a_blocks = submenu.find_all('a')\n",
    "\n",
    "        subdirectories = {}\n",
    "        for a_block in tqdm(a_blocks): \n",
    "            # each a_block represents one president, extract the subdirectory and save \n",
    "            # it under the president's name\n",
    "            subdirectories[a_block.text] = a_block['href']\n",
    "\n",
    "        self.subdirectories = subdirectories\n",
    "\n",
    "\n",
    "\n",
    "def getDataMiller(html):\n",
    "    soup = getSoup(html) # Parsing of given html utilizing BeautifulSoup \n",
    "\n",
    "    # Enter main navigation panel and find submenu that contains list of US presidents and following url 'ending' of their respective subsite\n",
    "    # Select second list to aim for desired list and remove duplicates due to multiple similar/same lists in the whole html\n",
    "    name_list = soup.find('nav',{'aria-labelledby':'block-mainnavigation-3-menu'}).find_all('ul',{'class':'submenu'})[1]\n",
    "\n",
    "    pres_dict = {} # Creation of empty dictionary\n",
    "    for pres in name_list.find_all('a'): \n",
    "        pres_dict[pres.text] = pres['href'] # extract and save names (key) and link 'endings' (value)\n",
    "    # dictionary_1 -> contains names and links on Millercenter of each US president\n",
    "    \n",
    "    \n",
    "    data_presidents = {}\n",
    "    for name,href in pres_dict.items():\n",
    "        # main loop: iterates names and link of presidents contained in previously created dictionary 'pres_dict'\n",
    "        # getting on the subsite of specific president\n",
    "        soup = getjoinSoupMiller(href)\n",
    "\n",
    "        #1 extraction of FAST FACTS dashboard of specific president\n",
    "        details = soup.find('div',{'class':'president-main-wrapper'}).find('div',{'class':'fast-facts-wrapper'})   \n",
    "\n",
    "        list_of_relevant_details = [x for x in list(details.children) if x != '\\n'] # removing redundant elements \n",
    "        list_of_relevant_details.pop(0) # removing first div with decsription\n",
    "\n",
    "        fast_facts = {}\n",
    "        for det in list_of_relevant_details:\n",
    "            fast_facts[det.label.text] = det.div.text # for loop to load details and specifics into dict (key: label of detail)\n",
    "\n",
    "        #2 brief description of the president\n",
    "        brief_desc = {}\n",
    "        brief_desc['Description'] = soup.find('div',{'class':'copy-wrapper'}).p.text # short description of president\n",
    "\n",
    "        #3 famous quote of the president\n",
    "        quote = {}\n",
    "        quote['Quote'] = soup.find('blockquote',{'class':'president-quote'}).contents[0]\n",
    "\n",
    "        #4 number of KEY EVENTS that happened during office\n",
    "        # extracting url 'ending' for subsite with notable events that happened at time of office\n",
    "        key_events = soup.find('div',{'class':'sub-nav-region'}).find_all('a')[1] \n",
    "        soup_1 = getjoinSoupMiller(key_events['href']) # getting into the list of key events of president\n",
    "\n",
    "        ke_count = {}\n",
    "        # count of number of major events that happened at time of office - key_events_count_X : ke_c_X  \n",
    "        # D. Trump page has no information about major events hence we included error exception   \n",
    "        # after some time they changed the notation when 'titles' are highlighted in bold\n",
    "        try:   \n",
    "            ke_c_1 = len(soup_1.find('div',{'class':'article-wysiwyg-body'}).find_all('strong')) # count of all events - highlighted by bolding\n",
    "            ke_c_2 = len(soup_1.find('div',{'class':'article-wysiwyg-body'}).find_all('b')) # notation change\n",
    "            ke_count['Number of major events'] = ke_c_1 + ke_c_2 # due to double 'bold' notation we sum the count\n",
    "        except AttributeError:\n",
    "            ke_count['Number of major events'] = 0\n",
    "            pass\n",
    "\n",
    "        data_presidents[name] = {**fast_facts,**brief_desc,**quote,**ke_count} #merge of the dictionaries\n",
    "        #dictionary_2 -> contains characteristics and facts about each US president, his brief description, famous quote and \n",
    "        #                count of notable events happened at time of his office\n",
    "        \n",
    "    return data_presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getjoinSoupPotus(link):\n",
    "    html = \"\".join(['https://www.potus.com/',link]) \n",
    "    response = requests.get(html)\n",
    "    return BeautifulSoup(response.text,'html.parser') \n",
    "\n",
    "def getDataPotus(html,typeofreturn):\n",
    "    soup = getSoup(html) # Parsing of given html utilizing BeautifulSoup \n",
    "\n",
    "    pres_list = {}\n",
    "    for pres in soup.find_all('a',{'target':'_self'}):\n",
    "        pres_list[pres.find('img')['alt']] = pres['href'] # extract and save names (key) and link 'endings' (value)\n",
    "\n",
    "    pres_list.pop('Facts About the Presidents') # removing first row as it is a title\n",
    "    # dictionary_1 -> includes names and links of each president\n",
    "    \n",
    "    \n",
    "    #1 main loop: iterates links from dictionary_1 and gathers data about US presidential election results and \n",
    "    #             presidential salary of each president - therefore it returns two outputs, conditional on the input value \n",
    "    elec_results = {} #creation of empty final dict of election results\n",
    "    salary = {}       #creation of empty dict for salaries\n",
    "    \n",
    "    for name,href in pres_list.items(): \n",
    "        soup = getjoinSoupPotus(href)\n",
    "\n",
    "        #2 extraction of salary each president received \n",
    "        if typeofreturn == 'salary':\n",
    "            #Benjamin Harrison has space in the string - error msg - therefore workaround is here\n",
    "            try:\n",
    "                salary[name] = soup.find(string=\"Presidential Salary:\").find_parent('p').text\n",
    "            except AttributeError:\n",
    "                salary[name] = soup.find(string=\"Presidential Salary: \").find_parent('p').text\n",
    "\n",
    "        #3 extraction of html tables of Presidential election results       \n",
    "        elif typeofreturn == 'election':\n",
    "            \n",
    "            elections = soup.find(string=\"Presidential Election Results:\").find_parent('div')\n",
    "\n",
    "            #3.1 extraction of results for individual years\n",
    "            for tbl in elections.find_all('table'): #selecting tables for individual years\n",
    "\n",
    "                year = tbl.find('tr',{'class','row-2'}).find('a').text #year extraction\n",
    "                electee_list = {}\n",
    "\n",
    "                #3.2 selecting row with individual candidate\n",
    "                for electee in tbl.find_all('tr'): \n",
    "                    try: # first row is header hence we include this exception skip it and to continue\n",
    "\n",
    "                        electee_name = electee.find('td',{'class':'column-2'}).a.text  # name of candidate\n",
    "                        electee_votes = {}\n",
    "\n",
    "                        #3.3 data contained in tables for results of elections further in the past do not include\n",
    "                        #  'popular votes' column, therefore it was necessary to include this condition\n",
    "                        if len(elections.find('tr').find_all('th')) == 3: \n",
    "                            electee_votes['popular_votes']   = \"\" \n",
    "                            # above: number of popular votes candidate gained\n",
    "                            electee_votes['electoral_votes'] = electee.find('td',{'class':'column-3'}).text\n",
    "                            # above: number of electoral votes candidate gained\n",
    "                        else:\n",
    "                            electee_votes['popular_votes']   = electee.find('td',{'class':'column-3'}).text   \n",
    "                            electee_votes['electoral_votes'] = electee.find('td',{'class':'column-4'}).text   \n",
    "\n",
    "                        electee_list[electee_name] = electee_votes \n",
    "                        \n",
    "                    except AttributeError: # first row is header hence we include this exception to continue\n",
    "                        pass\n",
    "                    \n",
    "                elec_results[year] = electee_list # writing in the results for given year    \n",
    "    \n",
    "    if typeofreturn == 'election':\n",
    "        return elec_results \n",
    "        # dictionary_2 -> contains results of elections grouped by years, states names of the candidates and respective votes \n",
    "        #                 gained\n",
    "    elif typeofreturn == 'salary':\n",
    "        return salary \n",
    "        # dictionary_3 -> contains information about salaries of each president (strings as it includes additional information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_presidents = getDataMiller('https://millercenter.org/') #execution time over 1 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_elections = getDataPotus('https://www.potus.com/','election') # execution time over 1 minute 35 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_salary = getDataPotus('https://www.potus.com/','salary') # execution time over 1 minute 35 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: manipulate the data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grover Cleveland was in office 2 non-consecutive times\n",
    "data_presidents['Grover Cleveland 2'] = {\n",
    "    key: value for key, value in data_presidents['Grover Cleveland'].items() if key not in ['Inauguration Date', 'Date Ended']\n",
    "}\n",
    "\n",
    "def correct_Grover_Cleveland_dates(data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    inauguration_date_1 = data['Grover Cleveland']['Inauguration Date'].split('\\n')[1]\n",
    "    inauguration_date_2 = data['Grover Cleveland']['Inauguration Date'].split('\\n')[3]\n",
    "    date_ended_1 = data['Grover Cleveland']['Date Ended'].split('\\n')[1]\n",
    "    date_ended_2 = data['Grover Cleveland']['Date Ended'].split('\\n')[3]\n",
    "\n",
    "    data['Grover Cleveland']['Inauguration Date'] = inauguration_date_1\n",
    "    data['Grover Cleveland 2']['Inauguration Date'] = inauguration_date_2\n",
    "    data['Grover Cleveland']['Date Ended'] = date_ended_1\n",
    "    data['Grover Cleveland 2']['Date Ended'] = date_ended_2\n",
    "\n",
    "    return data\n",
    "\n",
    "# run only once\n",
    "data_presidents = correct_Grover_Cleveland_dates(data_presidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final table with data extracted from https://millercenter.org\n",
    "# pd.DataFrame(data_presidents)\n",
    "\n",
    "data = pd.DataFrame(data_presidents).applymap(lambda x: x.replace('\\n', '') if isinstance(x, str) else x).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_variables = {\n",
    "    'Birth Place', \n",
    "    'Burial Place', \n",
    "    'Career', \n",
    "    'Children',\n",
    "    'Description', \n",
    "    'Education', \n",
    "    'Full Name',\n",
    "    'Marriage',\n",
    "    'Nickname',\n",
    "    'Political Party', \n",
    "    'Quote',\n",
    "    'Religion'\n",
    "}\n",
    "\n",
    "int_variables = {\n",
    "    'Number of major events',\n",
    "    'President Number'\n",
    "}\n",
    "\n",
    "timestamp_variables = {\n",
    "    'Birth Date',\n",
    "    'Date Ended', \n",
    "    'Death Date',\n",
    "    'Inauguration Date'\n",
    "}\n",
    "\n",
    "for str_variable in str_variables:\n",
    "    data[str_variable] = data[str_variable].map(str)\n",
    "\n",
    "for int_variable in int_variables:\n",
    "    data[int_variable] = data[int_variable].map(int)\n",
    "\n",
    "for timestamp_variable in timestamp_variables:\n",
    "    data[timestamp_variable] = data[timestamp_variable].map(pd.Timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Years at Inauguration'] = (data['Inauguration Date'] - data['Birth Date']).map(lambda x: x.days / 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make the visualizations here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_years_at_inauguration():\n",
    "    trace = plotly.graph_objs.Scatter(\n",
    "        x = data['Inauguration Date'],\n",
    "        y = data['Years at Inauguration'],\n",
    "        mode = 'lines+markers',\n",
    "        name = 'chart_a',\n",
    "        marker = {'size': 7},\n",
    "    )\n",
    "\n",
    "    layout = plotly.graph_objs.Layout(\n",
    "        title = 'Years at Inauguration',\n",
    "        yaxis = {'title': 'Years at Inauguration'},\n",
    "        xaxis = {'title': 'Inauguration Date'},\n",
    "    )\n",
    "\n",
    "    plotly.offline.iplot(plotly.graph_objs.Figure(\n",
    "        data = [trace],\n",
    "        layout = layout\n",
    "    ))\n",
    "\n",
    "plot_years_at_inauguration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number_of_major_events():\n",
    "    trace = plotly.graph_objs.Scatter(\n",
    "        x = data['Inauguration Date'],\n",
    "        y = data['Number of major events'],\n",
    "        mode = 'lines+markers',\n",
    "        name = 'chart_a',\n",
    "        marker = {'size': 7},\n",
    "    )\n",
    "\n",
    "    layout = plotly.graph_objs.Layout(\n",
    "        title = 'Number of major events',\n",
    "        yaxis = {'title': 'Number of major events'},\n",
    "        xaxis = {'title': 'Inauguration Date'},\n",
    "    )\n",
    "\n",
    "    plotly.offline.iplot(plotly.graph_objs.Figure(\n",
    "        data = [trace],\n",
    "        layout = layout\n",
    "    ))\n",
    "\n",
    "plot_number_of_major_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: conclude here?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
